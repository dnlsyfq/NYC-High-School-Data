{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is WINDOWS\n",
      " Volume Serial Number is 7CD4-C601\n",
      "\n",
      " Directory of C:\\Users\\dania\\Code\\Python\\NYC-High-School-Data\n",
      "\n",
      "13/01/2020  01:31 PM    <DIR>          .\n",
      "13/01/2020  01:31 PM    <DIR>          ..\n",
      "13/01/2020  01:30 PM    <DIR>          .ipynb_checkpoints\n",
      "13/01/2020  01:28 PM    <DIR>          archived\n",
      "13/01/2020  01:31 PM    <DIR>          schools\n",
      "13/01/2020  01:30 PM            17,775 Schools.ipynb\n",
      "               1 File(s)         17,775 bytes\n",
      "               5 Dir(s)  399,860,621,312 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import re\n",
    "\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for f in data_files:\n",
    "    d = pd.read_csv(\"schools/{0}\".format(f))\n",
    "    data[f.replace(\".csv\", \"\")] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ap_2010', 'class_size', 'demographics', 'graduation', 'hs_directory', 'sat_results'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dania\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "all_survey = pd.read_csv(\"schools/survey_all.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "d75_survey = pd.read_csv(\"schools/survey_d75.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "survey = pd.concat([all_survey, d75_survey], axis=0)\n",
    "\n",
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "\n",
    "survey_fields = [\n",
    "    \"DBN\", \n",
    "    \"rr_s\", \n",
    "    \"rr_t\", \n",
    "    \"rr_p\", \n",
    "    \"N_s\", \n",
    "    \"N_t\", \n",
    "    \"N_p\", \n",
    "    \"saf_p_11\", \n",
    "    \"com_p_11\", \n",
    "    \"eng_p_11\", \n",
    "    \"aca_p_11\", \n",
    "    \"saf_t_11\", \n",
    "    \"com_t_11\", \n",
    "    \"eng_t_11\", \n",
    "    \"aca_t_11\", \n",
    "    \"saf_s_11\", \n",
    "    \"com_s_11\", \n",
    "    \"eng_s_11\", \n",
    "    \"aca_s_11\", \n",
    "    \"saf_tot_11\", \n",
    "    \"com_tot_11\", \n",
    "    \"eng_tot_11\", \n",
    "    \"aca_tot_11\",\n",
    "]\n",
    "survey = survey.loc[:,survey_fields]\n",
    "data[\"survey\"] = survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>rr_s</th>\n",
       "      <th>rr_t</th>\n",
       "      <th>rr_p</th>\n",
       "      <th>N_s</th>\n",
       "      <th>N_t</th>\n",
       "      <th>N_p</th>\n",
       "      <th>saf_p_11</th>\n",
       "      <th>com_p_11</th>\n",
       "      <th>eng_p_11</th>\n",
       "      <th>...</th>\n",
       "      <th>eng_t_11</th>\n",
       "      <th>aca_t_11</th>\n",
       "      <th>saf_s_11</th>\n",
       "      <th>com_s_11</th>\n",
       "      <th>eng_s_11</th>\n",
       "      <th>aca_s_11</th>\n",
       "      <th>saf_tot_11</th>\n",
       "      <th>com_tot_11</th>\n",
       "      <th>eng_tot_11</th>\n",
       "      <th>aca_tot_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M034</td>\n",
       "      <td>89.0</td>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN  rr_s  rr_t  rr_p    N_s   N_t    N_p  saf_p_11  com_p_11  eng_p_11  \\\n",
       "0  01M015   NaN    88    60    NaN  22.0   90.0       8.5       7.6       7.5   \n",
       "1  01M019   NaN   100    60    NaN  34.0  161.0       8.4       7.6       7.6   \n",
       "2  01M020   NaN    88    73    NaN  42.0  367.0       8.9       8.3       8.3   \n",
       "3  01M034  89.0    73    50  145.0  29.0  151.0       8.8       8.2       8.0   \n",
       "4  01M063   NaN   100    60    NaN  23.0   90.0       8.7       7.9       8.1   \n",
       "\n",
       "   ...  eng_t_11  aca_t_11  saf_s_11  com_s_11  eng_s_11  aca_s_11  \\\n",
       "0  ...       7.6       7.9       NaN       NaN       NaN       NaN   \n",
       "1  ...       8.9       9.1       NaN       NaN       NaN       NaN   \n",
       "2  ...       6.8       7.5       NaN       NaN       NaN       NaN   \n",
       "3  ...       6.8       7.8       6.2       5.9       6.5       7.4   \n",
       "4  ...       7.8       8.1       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   saf_tot_11  com_tot_11  eng_tot_11  aca_tot_11  \n",
       "0         8.0         7.7         7.5         7.9  \n",
       "1         8.5         8.1         8.2         8.4  \n",
       "2         8.2         7.3         7.5         8.0  \n",
       "3         7.3         6.7         7.1         7.9  \n",
       "4         8.5         7.6         7.9         8.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['survey'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add DBN columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hs_directory\"][\"DBN\"] = data[\"hs_directory\"][\"dbn\"]\n",
    "\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return \"0\" + string_representation\n",
    "    \n",
    "data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']\n",
    "for c in cols:\n",
    "    data[\"sat_results\"][c] = pd.to_numeric(data[\"sat_results\"][c], errors=\"coerce\")\n",
    "\n",
    "data['sat_results']['sat_score'] = data['sat_results'][cols[0]] + data['sat_results'][cols[1]] + data['sat_results'][cols[2]]\n",
    "\n",
    "def find_lat(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lat = coords[0].split(\",\")[0].replace(\"(\", \"\")\n",
    "    return lat\n",
    "\n",
    "def find_lon(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lon = coords[0].split(\",\")[1].replace(\")\", \"\").strip()\n",
    "    return lon\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lat)\n",
    "data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lon)\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = pd.to_numeric(data[\"hs_directory\"][\"lat\"], errors=\"coerce\")\n",
    "data[\"hs_directory\"][\"lon\"] = pd.to_numeric(data[\"hs_directory\"][\"lon\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condense datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = data[\"class_size\"]\n",
    "class_size = class_size[class_size[\"GRADE \"] == \"09-12\"]\n",
    "class_size = class_size[class_size[\"PROGRAM TYPE\"] == \"GEN ED\"]\n",
    "\n",
    "class_size = class_size.groupby(\"DBN\").agg(numpy.mean)\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"] = class_size\n",
    "\n",
    "data[\"demographics\"] = data[\"demographics\"][data[\"demographics\"][\"schoolyear\"] == 20112012]\n",
    "\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Cohort\"] == \"2006\"]\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Demographic\"] == \"Total Cohort\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert AP scores to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "\n",
    "for col in cols:\n",
    "    data[\"ap_2010\"][col] = pd.to_numeric(data[\"ap_2010\"][col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = data[\"sat_results\"]\n",
    "\n",
    "combined = combined.merge(data[\"ap_2010\"], on=\"DBN\", how=\"left\")\n",
    "combined = combined.merge(data[\"graduation\"], on=\"DBN\", how=\"left\")\n",
    "\n",
    "to_merge = [\"class_size\", \"demographics\", \"survey\", \"hs_directory\"]\n",
    "\n",
    "for m in to_merge:\n",
    "    combined = combined.merge(data[m], on=\"DBN\", how=\"inner\")\n",
    "\n",
    "combined = combined.fillna(combined.mean())\n",
    "combined = combined.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a school district column for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_two_chars(dbn):\n",
    "    return dbn[0:2]\n",
    "\n",
    "combined[\"school_dist\"] = combined[\"DBN\"].apply(get_first_two_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAT Critical Reading Avg. Score    0.986820\n",
      "SAT Math Avg. Score                0.972643\n",
      "SAT Writing Avg. Score             0.987771\n",
      "sat_score                          1.000000\n",
      "AP Test Takers                     0.523140\n",
      "                                     ...   \n",
      "priority08                              NaN\n",
      "priority09                              NaN\n",
      "priority10                              NaN\n",
      "lat                               -0.121029\n",
      "lon                               -0.132222\n",
      "Name: sat_score, Length: 67, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = combined.corr()\n",
    "correlations = correlations[\"sat_score\"]\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting survey correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove DBN since it's a unique identifier, not a useful numerical value for correlation.\n",
    "survey_fields.remove(\"DBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
